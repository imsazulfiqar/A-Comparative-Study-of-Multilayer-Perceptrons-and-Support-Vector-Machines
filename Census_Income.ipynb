{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6f1aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install imbalanced-learn\n",
    "pip upgrade sklearn\n",
    "pip install scikit-plot\n",
    "# Importing all the libraries\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import scikitplot as skplt\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import validation_curve, learning_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a131217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data link: https://archive.ics.uci.edu/ml/datasets/adult ,download adult.data\n",
    "# Defining the columns names because the data file has no column names, so it makes it easier this way\n",
    "\n",
    "column_names = ['age','workclass','fnlwgt','education','education-num','marital-status','occupation','relationship','race','sex','capital-gain','capital-loss',\n",
    "'hours-per-week','native-country','income']\n",
    "\n",
    "# Please change the path below to the folder where you have downloaded the dataset in\n",
    "\n",
    "data = pd.read_csv(\"/Users/imsazulfiqar/Downloads/adult.data\", names=column_names)\n",
    "data\n",
    "\n",
    "# Checking for unique values and their frequency for the all variables\n",
    "\n",
    "for col in column_names:\n",
    "print(data[col].unique(),' ')\n",
    "print(data[col].value_counts())\n",
    "\n",
    "# Since education and education num are same, removing education\n",
    "\n",
    "data = data.drop('education', axis=1)\n",
    "\n",
    "# Relationship column does not look useful\n",
    "\n",
    "data = data.drop('relationship', axis=1)\n",
    "\n",
    "# ref:https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isin.html\n",
    "# Dropping the values with ? from the data\n",
    "\n",
    "data = data[~data.isin(['?']).any(axis=1)]\n",
    "data.shape\n",
    "\n",
    "# Checking data types of each variable\n",
    "data.dtypes\n",
    "\n",
    "# Checking for class imbalance\n",
    "target_percentage = data['income'].value_counts(normalize=True) * 100\n",
    "print(target_percentage)\n",
    "target_percentage.plot(kind='bar')\n",
    "plt.title(\"Distribution of target variable\")\n",
    "plt.xlabel(\"Income\")\n",
    "plt.ylabel(\"Percentage\")\n",
    "plt.show()\n",
    "\n",
    "# Using Label encoding for target variable since they are in order ;>50k or <=50k\n",
    "encoder = LabelEncoder()\n",
    "data['income'] = encoder.fit_transform(data['income'])\n",
    "\n",
    "# 0 for <=50k 1 for >50k\n",
    "encoder.classes_\n",
    "\n",
    "# Correlation heatmap to check the correlation of numeric values with the target column\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(data.corr(), cmap=\"rocket\", annot=True)\n",
    "plt.show()\n",
    "\n",
    "# Plotting distributions of numeric columns\n",
    "numerical_columns = ['age', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "data[numerical_columns].hist(bins=20, figsize=(15,10))\n",
    "plt.suptitle(\"Histograms of Numerical Columns\")\n",
    "plt.show()\n",
    "\n",
    "# FNLWGT does not show any correlation with the other numeric values, dropping it\n",
    "data = data.drop('fnlwgt', axis=1)\n",
    "\n",
    "# Removing capital gain and loss since they have 29849 and 31042 values as 0, which does not contribute in prediction\n",
    "\n",
    "data = data.drop('capital-loss', axis=1)\n",
    "data = data.drop('capital-gain', axis=1)\n",
    "\n",
    "# Making a copy of the current dataframe so no changes are made on the original data\n",
    "df=data.copy()\n",
    "\n",
    "# Plotting the relationship of age with income by making age ranges\n",
    "age_bins = [10, 19, 29, 39, 49, 59, 69, 79, 89]\n",
    "age_labels = ['10-19', '20-29', '30-39', '40-49', '50-59', '60-69', '70-79', '80+']\n",
    "df['agerange'] = pd.cut(df.age, bins=age_bins, labels = age_labels, include_lowest = True)\n",
    "ax=sns.countplot(x =\"agerange\", data = df,hue=\"income\")\n",
    "ax.set(xlabel='Age groups', ylabel='Number of Times Contacted')\n",
    "\n",
    "# ref:https://contactsunny.medium.com/label-encoder-vs-one-hot-encoder-in-machine-learning-3fc273365621\n",
    "# Using One-hot encoding for categorical columns because since there are different numbers in the same column,\n",
    "# the model will misunderstand the data to be in some kind of order, 0 < 1 < 2.\n",
    "\n",
    "categorical_columns = ['workclass', 'marital-status', 'occupation', 'race', 'sex', 'native-country']\n",
    "data = pd.get_dummies(data, columns=categorical_columns)\n",
    "numerical_columns_ = ['age', 'education-num', 'hours-per-week']\n",
    "\n",
    "# Partitioning the data into X and y\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]\n",
    "\n",
    "# Scaling the numerical features\n",
    "scaler = StandardScaler()\n",
    "X[numerical_columns_] = scaler.fit_transform(X[numerical_columns_])\n",
    "X\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "len(y_test)\n",
    "\n",
    "# ref: https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.RandomUnderSampler.html\n",
    "# Since the dataset is imbalanced, using random under-sampling to under-sample the majority class by\n",
    "# randomly picking samples with or without replacement.\n",
    "\n",
    "rus = RandomUnderSampler(sampling_strategy=1)\n",
    "X_res, y_res = rus.fit_resample(X_train, y_train)\n",
    "print('Resampled dataset shape %s' % len(y_res))\n",
    "\n",
    "# ref: https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n",
    "# ref: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "# Defining the MLP model with assiging 10% of data for validation\n",
    "\n",
    "mlp = MLPClassifier(validation_fraction=0.1, early_stopping=True)\n",
    "\n",
    "# Making a grid of the hyperparameters to tune\n",
    "\n",
    "parameters = {\n",
    "'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 100),(50, 50, 50),(100, 100, 100)],\n",
    "'alpha': [ 0.0001,0.001, 0.01],\n",
    "'activation': ['logistic','relu', 'tanh'],\n",
    "'solver': ['adam', 'sgd'],\n",
    "'learning_rate':['adaptive','invscaling'],\n",
    "'momentum':[0.1,0.5,1],\n",
    "}\n",
    "\n",
    "# Timing the execution\n",
    "start_time = time.time()\n",
    "\n",
    "# Performing grid search with 5 fold cross-validation\n",
    "grid_search_mlp = GridSearchCV(mlp, parameters, cv=5,scoring='accuracy',verbose=3,refit = True)\n",
    "\n",
    "# Fitting the model on the random sampled data\n",
    "grid_search_mlp.fit(X_res, y_res)\n",
    "\n",
    "# Ending the time and calculating the time elapsed\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(\"Elapsed time:\", elapsed_time)\n",
    "\n",
    "# ref: https://stackoverflow.com/questions/41475539/using-best-params-from-gridsearchcv\n",
    "# Printing the best hyperparameters chosen\n",
    "print(\"Best hyperparameters:\", grid_search_mlp.best_params_)\n",
    "\n",
    "# Fitting MLP on the best hyperparameters\n",
    "mlp = MLPClassifier(**grid_search_mlp.best_params_)\n",
    "mlp.fit(X_res, y_res)\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "# Printing the loss computed with the loss function\n",
    "print('Loss: ',mlp.loss_)\n",
    "\n",
    "# Plotting the loss curve\n",
    "plt.figure()\n",
    "plt.plot(mlp.loss_curve_)\n",
    "plt.title(\"Loss Curve (MLP)\")\n",
    "plt.xlabel(\"Number of iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()\n",
    "\n",
    "# ref:https://campus.datacamp.com/courses/hyperparameter-tuning-in-python/grid-search?ex=10\n",
    "# Getting the mean test scores for each hyperparameter combination\n",
    "mean_test_scores = grid_search_mlp.cv_results_['mean_test_score']\n",
    "\n",
    "# Sorting the mean test scores list in descending order to get the highest scores first\n",
    "sorted_indices = np.argsort(mean_test_scores)[::-1]\n",
    "\n",
    "# Getting the top 18 hyperparameter combinations based on their performance in cross validation\n",
    "params_list = grid_search_mlp.cv_results_['params']\n",
    "top_18_hyperparams = []\n",
    "for index in sorted_indices[:18]:\n",
    "top_18_hyperparams.append(params_list[index])\n",
    "\n",
    "# Calculating the validation accuracies for the top hyperparameters extracted\n",
    "validation_accuracies = []\n",
    "for hyperparams in top_18_hyperparams:\n",
    "mlp = MLPClassifier(**hyperparams)\n",
    "mlp.fit(X_res, y_res)\n",
    "y_pred = mlp.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)*100\n",
    "validation_accuracies.append(accuracy)\n",
    "\n",
    "# Combining the hyperparameters and their validation accuracies in a list\n",
    "results = list(zip(top_18_hyperparams, validation_accuracies))\n",
    "results\n",
    "\n",
    "# ref:https://scikit-learn.org/stable/auto_examples/model_selection/plot_validation_curve.html\n",
    "# Plotting the validation curve for MLP on the best hyperparameters for values\n",
    "# of alpha since its the regularization constant\n",
    "# Plotting on a logarithmic scale\n",
    "\n",
    "param_range = np.logspace(-5, 3, 9)\n",
    "\n",
    "# Calculating the training and validation scores for each alpha value in the param_range.\n",
    "train_scores, val_scores = validation_curve(mlp,X_res, y_res, param_name=\"alpha\",param_range=param_range,cv=5)\n",
    "\n",
    "# Calculating the mean training and validation scores for each alpha value.\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "val_mean = np.mean(val_scores, axis=1)\n",
    "\n",
    "# Ploting the validation scores on the same semilogarithmic scale to observe\n",
    "# the differences in performance for very small values of alpha\n",
    "plt.semilogx(param_range, train_mean, label=\"Training score\", color=\"darkorange\")\n",
    "plt.semilogx(param_range, val_mean, label=\"Validation score\", color=\"navy\")\n",
    "plt.title(\"Validation Curve for MLP\")\n",
    "plt.xlabel(\"Alpha\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#ref: #ref:https://scikit-plot.readthedocs.io/en/stable/metrics.html\n",
    "# Evaluation metrics on test data\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "\n",
    "# Plotting the ROC curve for MLP\n",
    "Predict = mlp.predict_proba(X_test)\n",
    "skplt.metrics.plot_roc(y_test, Predict)\n",
    "\n",
    "# Plotting the confusion matrix for MLP\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_display = ConfusionMatrixDisplay(cm).plot()\n",
    "\n",
    "# Classification report for MLP\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# ref: https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC\n",
    "# ref: https://stackoverflow.com/questions/30972029/how-does-the-class-weight-parameter-in-scikit-learn-work\n",
    "# Defining the SVM model setting the class weight to balanced to help with the imbalanced class problem\n",
    "svm = SVC(random_state=10,class_weight='balanced')\n",
    "\n",
    "# Making a grid of the hyperparameters to tune\n",
    "param_grid = {\n",
    "'C': [0.01, 0.1, 1, 10, 100],\n",
    "'tol': [1e-4, 1e-3, 1e-2],\n",
    "'kernel':['linear', 'poly', 'rbf', 'sigmoid']\n",
    "}\n",
    "\n",
    "# Timing the execution\n",
    "start_time = time.time()\n",
    "\n",
    "# Performing grid search with 5 fold cross-validation\n",
    "grid_search_svm = GridSearchCV(svm, param_grid, cv=5, scoring='accuracy', refit = True, verbose = 4,return_train_score=True)\n",
    "\n",
    "# Fitting the model on the random sampled data\n",
    "grid_search_svm.fit(X_res, y_res)\n",
    "\n",
    "# Ending the time and calculating the time elapsed\n",
    "end_time = time.time()\n",
    "elapsed_time_svm = end_time - start_time\n",
    "\n",
    "# Printing the best hyperparameters chosen\n",
    "print(\"Best hyperparameters:\", grid_search_svm.best_params_)\n",
    "\n",
    "# Fitting SVM on the best hyperparameters\n",
    "svm = SVC(**grid_search_svm.best_params_,probability=True)\n",
    "svm.fit(X_res, y_res)\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Getting the mean test scores for each hyperparameter combination\n",
    "mean_test_scores = grid_search_svm.cv_results_['mean_test_score']\n",
    "\n",
    "# Sorting the mean test scores list in descending order to get the highest scores first\n",
    "sorted_indices = np.argsort(mean_test_scores)[::-1]\n",
    "\n",
    "# Getting the top 18 hyperparameter combinations based on their performance in cross validation\n",
    "params_list = grid_search_svm.cv_results_['params']\n",
    "top_18_hyperparams = []\n",
    "for index in sorted_indices[:18]:\n",
    "top_18_hyperparams.append(params_list[index])\n",
    "\n",
    "# Calculating the validation accuracies for the top hyperparameters extracted\n",
    "validation_accuracies = []\n",
    "for hyperparams in top_18_hyperparams:\n",
    "svm = SVC(**hyperparams, probability= True)\n",
    "svm.fit(X_res, y_res)\n",
    "y_pred = svm.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)*100\n",
    "validation_accuracies.append(accuracy)\n",
    "\n",
    "# Combining the hyperparameters and their validation accuracies in a list\n",
    "results = list(zip(top_18_hyperparams, validation_accuracies))\n",
    "results\n",
    "\n",
    "# Plotting the validation curve for SVM on the best hyperparameters for values\n",
    "# of C since its the regularization constant\n",
    "# Plotting on a logarithmic scale\n",
    "param_range = np.logspace(-6, 1, 8)\n",
    "\n",
    "# Calculating the training and validation scores for each C value in the param_range.\n",
    "train_scores, test_scores = validation_curve(svm, X_res, y_res, param_name='C', param_range=param_range, cv=5)\n",
    "\n",
    "# Calculating the mean training and validation scores for each C value.\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "\n",
    "# Ploting the validation scores on the same semilogarithmic scale to observe\n",
    "# the differences in performance for very small values of C\n",
    "plt.semilogx(param_range, train_mean, label='Training score', color='blue')\n",
    "plt.semilogx(param_range, test_mean, label='Cross-validation score', color='red')\n",
    "plt.title('Validation curve for SVM')\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Score')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "# Evaluation metrics on test data\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "\n",
    "# Plotting the ROC curve for SVM\n",
    "Predict = svm.predict_proba(X_test)\n",
    "skplt.metrics.plot_roc(y_test, Predict)\n",
    "\n",
    "# Plotting the confusion matrix for SVM\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_display = ConfusionMatrixDisplay(cm).plot()\n",
    "\n",
    "# Classification report for SVM\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Plotting the decision function values for the test set\n",
    "decision_values = svm.decision_function(X_test)\n",
    "plt.hist(decision_values, bins=50)\n",
    "plt.xlabel(\"Decision Function Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60b451f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
